{
 "metadata": {
  "hex_info": {
   "author": "Vinod Shiv",
   "exported_date": "Wed Mar 01 2023 16:17:41 GMT+0000 (Coordinated Universal Time)",
   "project_id": "02a3affe-3893-407d-a4c2-10ff79a80636",
   "version": "draft"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "name": "cell1"
   },
   "source": [
    "# Data Engineering with Snowpark - Python\n",
    "\n",
    "This notebook utilizes Snowflake Snowpark for Python to:\n",
    "- Load raw parquet data files into Snowflake from S3\n",
    "- Create a harmonized work-area to merge change-data (CDC) over views\n",
    "- Create a denormalized table for analytics downstream\n",
    "\n",
    "\n",
    "#### A more comprehensive version of this notebook can be found [here](https://quickstarts.snowflake.com/guide/data_engineering_pipelines_with_snowpark_python/index.html?index=..%2F..index#0) as a Snowflake Quickstart\n"
   ],
   "id": "c6c5ea86-a650-4288-b8e3-08cf80beae86"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "name": "cell2"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1 - Import Necessary Libraries\n",
    "\n",
    "If any of the packages do not exist in your Python environment you can install them using conda or pip. \n",
    "Here is an example of installing seaborn visualization package\n",
    "\n",
    "!conda install --yes --prefix {sys.prefix} seaborn*"
   ],
   "id": "f04f2412-1d63-4818-8163-1336357c5db3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "name": "cell3",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "#import from snowflake.snowpark.types\n",
    "from snowflake.snowpark.types import *\n",
    "from snowflake.snowpark.version import VERSION\n",
    "\n",
    "# Pandas & json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Plotting\n",
    "import plotly.express as px\n",
    "\n",
    "# Time\n",
    "import time"
   ],
   "id": "b9b81243-fc25-4dd6-9271-604b90865772"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "name": "cell4"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 2 - Connect to Snowflake\n",
    "\n",
    "A json file contains credentials locally, using which a Snowpark session is created"
   ],
   "id": "a3ef09e5-cc17-4b47-b884-baa12d14a13f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "name": "cell5",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Read credentials\n",
    "with open(\"creds_vshiv.json\") as f:\n",
    "    connection_parameters = json.load(f)\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ],
   "id": "a3766153-26ec-4772-854e-6790511b0b55"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "name": "cell6",
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database.Schema  : \"HOL_DB\".\"ANALYTICS\"\n",
      "Warehouse \t : \"HOL_WH\"\n",
      "Role \t\t : \"HOL_ROLE\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Statement executed successfully.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Session details\n",
    "print(f'Database.Schema  : {session.get_fully_qualified_current_schema()}')\n",
    "print(f'Warehouse \\t : {session.get_current_warehouse()}')\n",
    "print(f'Role \\t\\t : {session.get_current_role()}')\n",
    "\n",
    "session.sql(\"ALTER WAREHOUSE HOL_WH SET WAREHOUSE_SIZE = SMALL\").collect()[0][0]\n"
   ],
   "id": "3d2e1738-b622-4f5e-90fa-7bd66e8892c8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "name": "cell7",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "## Test loading all in one\n",
    "\n",
    "# Optional - if the database needs to be torndown and recreated\n",
    "DASHES = '-'*50\n",
    "session.sql(\"CREATE OR REPLACE DATABASE HOL_DB\").collect()\n",
    "\n",
    "\n",
    "# -- Schemas\n",
    "session.sql(\"CREATE OR REPLACE SCHEMA EXTERNAL\").collect()\n",
    "session.sql(\"CREATE OR REPLACE SCHEMA RAW_POS\").collect()\n",
    "session.sql(\"CREATE OR REPLACE SCHEMA RAW_CUSTOMER\").collect()\n",
    "session.sql(\"CREATE OR REPLACE SCHEMA HARMONIZED\").collect()\n",
    "session.sql(\"CREATE OR REPLACE SCHEMA ANALYTICS\").collect()\n",
    "\n",
    "# -- External Frostbyte objects\n",
    "session.sql(\n",
    "    \"CREATE OR REPLACE FILE FORMAT EXTERNAL.PARQUET_FORMAT\\\n",
    "    TYPE = PARQUET\\\n",
    "    COMPRESSION = SNAPPY\"\n",
    ").collect()\n",
    "\n",
    "session.sql(\n",
    "    \"CREATE OR REPLACE STAGE EXTERNAL.FROSTBYTE_RAW_STAGE\\\n",
    "     URL = 's3://sfquickstarts/data-engineering-with-snowpark-python/'\"\n",
    ").collect();\n",
    "\n",
    "\n",
    "# Define locations and objects\n",
    "POS_TABLES = [\n",
    "    \"country\",\n",
    "    \"franchise\",\n",
    "    \"location\",\n",
    "    \"menu\",\n",
    "    \"truck\",\n",
    "    # \"order_header\",\n",
    "    # \"order_detail\"\n",
    "    ]\n",
    "\n",
    "TABLE_DICT = {\"pos\": {\"schema\": \"RAW_POS\", \"tables\": POS_TABLES}}\n"
   ],
   "id": "7a147a28-16bd-442e-8583-c13d6e4b9336"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "name": "cell8",
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Loading ['HOL_DB', 'RAW_POS', 'country']..\n",
      "--------------------------------------------------\n",
      "\n",
      "Completed!\n",
      "Status     : LOADED\n",
      "Rows Parsed: 30\n",
      "Rows Loaded: 30\n",
      "Errors Seen: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "Loading ['HOL_DB', 'RAW_POS', 'franchise']..\n",
      "--------------------------------------------------\n",
      "\n",
      "Completed!\n",
      "Status     : LOADED\n",
      "Rows Parsed: 335\n",
      "Rows Loaded: 335\n",
      "Errors Seen: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "Loading ['HOL_DB', 'RAW_POS', 'location']..\n",
      "--------------------------------------------------\n",
      "\n",
      "Completed!\n",
      "Status     : LOADED\n",
      "Rows Parsed: 13,093\n",
      "Rows Loaded: 13,093\n",
      "Errors Seen: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "Loading ['HOL_DB', 'RAW_POS', 'menu']..\n",
      "--------------------------------------------------\n",
      "\n",
      "Completed!\n",
      "Status     : LOADED\n",
      "Rows Parsed: 100\n",
      "Rows Loaded: 100\n",
      "Errors Seen: 0\n",
      "\n",
      "--------------------------------------------------\n",
      "Loading ['HOL_DB', 'RAW_POS', 'truck']..\n",
      "--------------------------------------------------\n",
      "\n",
      "Completed!\n",
      "Status     : LOADED\n",
      "Rows Parsed: 450\n",
      "Rows Loaded: 450\n",
      "Errors Seen: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "for s3dir, data in TABLE_DICT.items():\n",
    "    tnames = data[\"tables\"]\n",
    "    schema = data[\"schema\"]\n",
    "\n",
    "    for tname in tnames:\n",
    "        location = \"@external.frostbyte_raw_stage/\"+s3dir+\"/\"+tname\n",
    "\n",
    "        tname = ['HOL_DB', schema, tname]\n",
    "        print(f'\\n{DASHES}\\nLoading {tname}..\\n{DASHES}\\n')\n",
    "\n",
    "        df = session.read.option(\"compression\", \"snappy\").parquet(location)\n",
    "        copied_into_result = df.copy_into_table(tname)\n",
    "    \n",
    "        # Print result\n",
    "        out_dict = copied_into_result[0].asDict()\n",
    "        print(\"Completed!\")\n",
    "        \n",
    "        for i in out_dict:\n",
    "            if i in ['status']:\n",
    "                print(f\"{i.replace('_',' ').title()}     : {out_dict[i]}\")\n",
    "            elif i in ['rows_loaded','rows_parsed','errors_seen']:\n",
    "                print(f\"{i.replace('_',' ').title()}: {out_dict[i]:,}\")"
   ],
   "id": "b8aa91de-12c4-4836-a692-158d242c647a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell9",
    "language": "python"
   },
   "outputs": [],
   "source": [],
   "id": "1ea0e2f4-4fff-4579-bd4f-b7c17e893e2a"
  }
 ]
}